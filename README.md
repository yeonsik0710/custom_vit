# Data-aware Sparsity for ViT: Efficient Algorithm-HW Co-design with Windowed Attention
## :rocket:Poster
![image](https://github.com/yeonsik0710/custom_vit/blob/main/img/poster.png)

## :thumbsup:Reference
1. H. You, et al., "ViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and Accelerator Co-Design." in IEEE, 2023.
2. H. Touvron, et al., "Training data-efficient image transformers & distillation through attention." in PMLR, 2021. 
