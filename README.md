# :sparkles:Setting
<details>
<summary>
  <a href="README_deit.md">DeiT</a> Data-Efficient Image Transformers, ICML 2021 [<b>bib</b>]
</summary>
  
```
@InProceedings{pmlr-v139-touvron21a,
  title =     {Training data-efficient image transformers &amp; distillation through attention},
  author =    {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
  booktitle = {International Conference on Machine Learning},
  pages =     {10347--10357},
  year =      {2021},
  volume =    {139},
  month =     {July}
}
```
</details>

<br>

# :rocket:Poster
![image](https://github.com/yeonsik0710/custom_vit/blob/main/img/poster.png)

<br>

# :thumbsup:Reference
1. H. You, et al., "ViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and Accelerator Co-Design." in IEEE, 2023.
2. H. Touvron, et al., "Training data-efficient image transformers & distillation through attention." in PMLR, 2021. 
